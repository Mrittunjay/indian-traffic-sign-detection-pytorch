{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNfUjQnUf04qvljIwVV8bZm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c47d9cf639d644ef8284ead30faab494":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_081e69b1e7fb4df5a83ec612ced8fcdf","IPY_MODEL_9a6abadda4214a58a5c92f8e1c3e6d8e","IPY_MODEL_34f2848bd44c446bad888151cdd19f61"],"layout":"IPY_MODEL_6049197dd9fa4547827a5049f84fb49c"}},"081e69b1e7fb4df5a83ec612ced8fcdf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d3d8d9a2abe4d1c94792870e7b02ad5","placeholder":"​","style":"IPY_MODEL_476214ccb4cd40c2b16829e8834e8a4e","value":"  0%"}},"9a6abadda4214a58a5c92f8e1c3e6d8e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6a5ef260c5542258640ce291bcfe03b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_32a8b8d30e0a4573ab4a6d44f995b358","value":0}},"34f2848bd44c446bad888151cdd19f61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a92f1c514e940c28d41716f0b60cfaa","placeholder":"​","style":"IPY_MODEL_cb8560d3080a4d7cb35ccd285ffdc8b8","value":" 0/1 [00:00&lt;?, ?it/s]"}},"6049197dd9fa4547827a5049f84fb49c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d3d8d9a2abe4d1c94792870e7b02ad5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"476214ccb4cd40c2b16829e8834e8a4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6a5ef260c5542258640ce291bcfe03b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32a8b8d30e0a4573ab4a6d44f995b358":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a92f1c514e940c28d41716f0b60cfaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb8560d3080a4d7cb35ccd285ffdc8b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Image Detection\n","This project is to train a deep learning model to detecta and classify road sign in indian road.\n","\n","Dataset used for this project is `Indian Traffic Sign Dataset` from Kaggle : https://www.kaggle.com/datasets/neelpratiksha/indian-traffic-sign-dataset?resource=download"],"metadata":{"id":"RCEd9aGz8F0S"}},{"cell_type":"code","source":["# Loading data from drive(mounting the google drive to our project)\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8R6y9iD8lvf","executionInfo":{"status":"ok","timestamp":1708574009671,"user_tz":-330,"elapsed":38576,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}},"outputId":"bd563bc9-8ea5-4e53-887d-35709db3f779"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Folder containing all the images in folder format\n","data_path = '/content/drive/MyDrive/project/traffic-road-sign-detection/indian-traffic-sign-dataset/Images'"],"metadata":{"id":"LvLgaybp-VKX","executionInfo":{"status":"ok","timestamp":1708574009673,"user_tz":-330,"elapsed":14,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# csv file contains the folder number mapped to class name\n","labels_path = '/content/drive/MyDrive/project/traffic-road-sign-detection/indian-traffic-sign-dataset/traffic_sign.csv'"],"metadata":{"id":"HwZBA-JV--JD","executionInfo":{"status":"ok","timestamp":1708574009674,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["4# Importing important laibaries\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","from torch import nn, optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n","\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm"],"metadata":{"id":"Lnai1mm1s_5k","executionInfo":{"status":"ok","timestamp":1708574018429,"user_tz":-330,"elapsed":8765,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["labels_df = pd.read_csv(labels_path)\n","labels_df.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"WrgnB6hstEd9","executionInfo":{"status":"ok","timestamp":1708574019157,"user_tz":-330,"elapsed":737,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}},"outputId":"bbd1fd93-ceeb-4b37-a32e-8dad863396c5"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   ClassId                            Name\n","0        0                        Give way\n","1        1                        No entry\n","2        2                 One-way traffic\n","3        3                 One-way traffic\n","4        4  No vehicles in both directions"],"text/html":["\n","  <div id=\"df-7f7ccdba-29b9-4f77-beef-44c197b9981d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ClassId</th>\n","      <th>Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Give way</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>No entry</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>One-way traffic</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>One-way traffic</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>No vehicles in both directions</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f7ccdba-29b9-4f77-beef-44c197b9981d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7f7ccdba-29b9-4f77-beef-44c197b9981d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7f7ccdba-29b9-4f77-beef-44c197b9981d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f307aad7-f873-4bde-b1c3-b7f0ad2eb0b9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f307aad7-f873-4bde-b1c3-b7f0ad2eb0b9')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f307aad7-f873-4bde-b1c3-b7f0ad2eb0b9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"labels_df","summary":"{\n  \"name\": \"labels_df\",\n  \"rows\": 59,\n  \"fields\": [\n    {\n      \"column\": \"ClassId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 0,\n        \"max\": 58,\n        \"num_unique_values\": 59,\n        \"samples\": [\n          0,\n          5,\n          34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 52,\n        \"samples\": [\n          \"Horn prohibited\",\n          \"Guarded level crossing ahead\",\n          \"Telephone\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Data Transformations\n","transform = transforms.Compose([\n","    transforms.Resize((32, 32)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        mean=[0.5],\n","        std=[0.5])\n","])"],"metadata":{"id":"aGrFJDTqtPbK","executionInfo":{"status":"ok","timestamp":1708574019159,"user_tz":-330,"elapsed":21,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Device agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"ifeC4mqOM7gz","executionInfo":{"status":"ok","timestamp":1708574019160,"user_tz":-330,"elapsed":21,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}},"outputId":"5254887b-5935-42c8-e201-8f9fa7d63a5b"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["###The following custom dataset class is created because I was facing problem while loading the dataset as a dataloader for my model. The labels and the images were not matching when plain datasets.ImageFolder was used over the dataset"],"metadata":{"id":"fAH11Ui5c9mZ"}},{"cell_type":"markdown","source":["# Temporary note: change the getitem function to extract the folder name rather then extracting the number in file name, because there are few images having wrong names"],"metadata":{"id":"P8-E0b0X75as"}},{"cell_type":"code","source":["from PIL import Image\n","import os\n","import re\n","\n","# Define a custom dataset class\n","class CustomTrafficSignDataset(Dataset):\n","    def __init__(self, root_dir, transform=None, split_percentage=0.8, train=True):\n","        # Create an ImageFolder dataset using torchvision\n","        self.dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n","\n","        self.transform = transform\n","        self.train = train\n","        self.split_percentage = split_percentage\n","\n","        # Calculate split index based on split percentage\n","        split_index = int(len(self.dataset) * self.split_percentage)\n","\n","        if self.train:\n","            self.data = self.dataset.imgs[:split_index]\n","        else:\n","            self.data = self.dataset.imgs[split_index:]\n","\n","    def __len__(self):\n","        # Return the length of the dataset\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_path, _ = self.data[idx]  # Get the image path and ignore the label from ImageFolder\n","\n","        # Extract label from the folder name (which is just a number)\n","        folder_name = os.path.basename(os.path.dirname(img_path))\n","        label = int(folder_name)\n","\n","        img = Image.open(img_path).convert('L')  # Convert to grayscale\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        return img, label\n","\n","    # def __getitem__(self, idx):\n","    #     img_path = self.data[idx][0]\n","    #     folder_name = os.path.basename(os.path.dirname(img_path))\n","\n","    #     # Extracting the first numeric sequence from the folder name\n","    #     # using regular expressing\n","    #     label_match = re.search(r'\\d+', folder_name)\n","    #     # Default to zero if no numeric value is found\n","    #     label = int(label_match.group()) if label_match else 0\n","\n","    #     img = Image.open(img_path).convert('L') # convert to gray scale\n","\n","    #     if self.transform:\n","    #         img=self.transform(img)\n","\n","    #     return img, label"],"metadata":{"id":"E7HwDJeNZO_K","executionInfo":{"status":"ok","timestamp":1708574019161,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Creating an instance of custom dataset for training\n","train_dataset = CustomTrafficSignDataset(root_dir=data_path,\n","                                         transform=transform,\n","                                         split_percentage=0.8,\n","                                         train=True)\n","# Creating an instance of custom dataset for validation\n","validation_dataset = CustomTrafficSignDataset(root_dir=data_path,\n","                                              transform=transform,\n","                                              split_percentage=0.8,\n","                                              train=False)\n","len(train_dataset), len(validation_dataset)"],"metadata":{"id":"vmdF4olHouOl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708574040947,"user_tz":-330,"elapsed":21804,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}},"outputId":"66801120-4bb9-4917-cc64-d2df59306d63"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9326, 2332)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["BATCH_SIZE = 32\n","# Creating training data loader\n","train_loader = DataLoader(train_dataset,\n","                          batch_size=BATCH_SIZE,\n","                          shuffle=True)\n","# Creating validation data loader\n","validation_loader = DataLoader(validation_dataset,\n","                         batch_size=BATCH_SIZE,\n","                         shuffle=False)\n","len(train_loader), len(validation_loader)"],"metadata":{"id":"JLb56f3wqSI-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708574040947,"user_tz":-330,"elapsed":42,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}},"outputId":"38553c07-7425-446e-a39c-b0914b2ab8cd"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(292, 73)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Get a batch of data from the train_loader\n","images, labels = next(iter(train_loader))\n","\n","# Choose a random index within the batch\n","random_index_within_batch = 0  # Adjust as needed\n","\n","# Extract the random image and label\n","random_image = images[random_index_within_batch]\n","random_label = labels[random_index_within_batch]\n","\n","# Convert the PyTorch tensor to a NumPy array for visualization\n","random_image_np = random_image.squeeze().numpy()\n","\n","# Denormalize the image\n","mean = 0.5\n","std = 0.5\n","sample_image = random_image_np * std + mean\n","\n","class_label = random_label.item()\n","class_info = labels_df[labels_df['ClassId']==class_label]['Name']\n","print(f\"class_info: {class_info}\\n\")\n","class_name = class_info.iloc[0]\n","print(f\"Class name: {class_name}\")\n","\n","# Print the label and display the image\n","print(f'Random Label: {class_label}')\n","plt.imshow(sample_image, cmap='gray')  # Specify cmap for grayscale\n","plt.title(class_name)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"Zg3Gd_oFrtkK","executionInfo":{"status":"ok","timestamp":1708574051626,"user_tz":-330,"elapsed":10715,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}},"outputId":"7df838b8-4999-4543-a429-be13816abba5"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["class_info: 13    Axle weight limit\n","Name: Name, dtype: object\n","\n","Class name: Axle weight limit\n","Random Label: 13\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# Checking device\n","print(next(iter(train_loader))[0].device)"],"metadata":{"id":"WYqXEERDLcDW","executionInfo":{"status":"ok","timestamp":1708574061752,"user_tz":-330,"elapsed":10140,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b99f57d2-070e-4e30-ab30-3d1680e5aece"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"markdown","source":["# Model 1: Convolutional Neural Network model for classification\n","Model Source : https://poloclub.github.io/cnn-explainer/"],"metadata":{"id":"gfkitZZ5RRyJ"}},{"cell_type":"code","source":["# Creating CNN model\n","class TrafficSignalClassificationModelV1(nn.Module):\n","    \"\"\"\n","    Model architecture is inspired from TineyVGG model from\n","    CNN explainer website\n","    \"\"\"\n","    def __init__(self,\n","                 input_shape: int,\n","                 hidden_units: int,\n","                 output_shape: int):\n","        super().__init__()\n","        self.conv_block_1 = nn.Sequential(\n","            nn.Conv2d(in_channels=input_shape,\n","                      out_channels=hidden_units,\n","                      kernel_size=3,  # The kernel size 3 is equivalent to (3, 3) touple, same as 3x3 matrix\n","                      stride=1,\n","                      padding=1),      # kernel_size, stride, padding are the Conv2d hyperparameters\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=hidden_units,\n","                      out_channels=hidden_units,\n","                      kernel_size=3,\n","                      stride=1,\n","                      padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","        )\n","        self.conv_block_2 = nn.Sequential(\n","            nn.Conv2d(in_channels=hidden_units,\n","                      out_channels=hidden_units,\n","                      kernel_size=3,\n","                      stride=1,\n","                      padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=hidden_units,\n","                      out_channels=hidden_units,\n","                      kernel_size=3,\n","                      stride=1,\n","                      padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(in_features=hidden_units * 8 * 8,\n","                      out_features=output_shape)\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv_block_1(x)\n","        # print(f\"Output shape of conv_block_1: {x.shape}\")\n","        x = self.conv_block_2(x)\n","        # print(f\"Output shape of conv_block_2: {x.shape}\")\n","        x = self.classifier(x)\n","        # print(f\"Output shape of clsssifier: {x.shape}\")\n","        return x"],"metadata":{"id":"cjFWTlJ0zwoW","executionInfo":{"status":"ok","timestamp":1708574061753,"user_tz":-330,"elapsed":82,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Running a forward pass to figure out the final linear layer in_features shapes\n","dummy_traffic_symbol_model = TrafficSignalClassificationModelV1(input_shape=1,\n","                                                          hidden_units=10,\n","                                                          output_shape=len(labels_df['ClassId'])).to(device)\n","next(dummy_traffic_symbol_model.parameters()).device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4DOxdTK-smkS","executionInfo":{"status":"ok","timestamp":1708574061753,"user_tz":-330,"elapsed":79,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}},"outputId":"eae0d83c-33ed-4af1-9604-c9031a72c11b"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["random_image.unsqueeze(dim=0).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38S8t3PTukpA","executionInfo":{"status":"ok","timestamp":1708574061754,"user_tz":-330,"elapsed":49,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}},"outputId":"284ad389-2944-49eb-97af-76e619415cf4"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 1, 32, 32])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# Running sample image through a forward pass\n","dummy_traffic_symbol_model(random_image.unsqueeze(dim=0).to(device))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88pTL3IZtyyz","executionInfo":{"status":"ok","timestamp":1708574061755,"user_tz":-330,"elapsed":46,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}},"outputId":"763e051c-f609-4a1a-d530-44951dfa1afd"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0369, -0.0565,  0.0113,  0.0556,  0.0946, -0.0137, -0.0317, -0.0052,\n","          0.0007,  0.0609,  0.0503, -0.0015,  0.0298, -0.0426, -0.0306, -0.0193,\n","          0.0104, -0.0162,  0.0942, -0.0168, -0.0108, -0.0313,  0.0436,  0.0538,\n","         -0.0189,  0.0166,  0.0123, -0.0379, -0.0256, -0.0804,  0.0592,  0.0514,\n","         -0.0454, -0.0157, -0.0513, -0.0089,  0.0252,  0.0638,  0.0453, -0.0036,\n","         -0.0453, -0.0580,  0.0501, -0.0235,  0.0243,  0.0062, -0.0496, -0.0085,\n","         -0.0140,  0.0363, -0.0121, -0.0265,  0.0785, -0.0089,  0.0332,  0.0122,\n","          0.0489,  0.0181, -0.0105]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## The final layer input feature shape should be `hidden_units*8*8`"],"metadata":{"id":"7SG0qE2TyceT"}},{"cell_type":"code","source":["# Total number of classes\n","total_classes = len(labels_df['ClassId'])\n","print(f\"Total classes : {total_classes}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QXlfyeLK5Y-k","executionInfo":{"status":"ok","timestamp":1708574061755,"user_tz":-330,"elapsed":43,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}},"outputId":"857a7cf0-edd0-4743-9794-84ce24cc10c7"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Total classes : 59\n"]}]},{"cell_type":"code","source":["# Inidializing our model\n","SEED_VALUE = 50\n","torch.manual_seed(SEED_VALUE)\n","\n","sign_class_model_v1 = TrafficSignalClassificationModelV1(input_shape=1,\n","                                                      hidden_units=10,\n","                                                      output_shape=total_classes).to(device)\n","sign_class_model_v1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4I0ax9Qf32R3","executionInfo":{"status":"ok","timestamp":1708574061756,"user_tz":-330,"elapsed":40,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}},"outputId":"2b4fd899-fdcf-4594-8a73-d888ba1872f9"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TrafficSignalClassificationModelV1(\n","  (conv_block_1): Sequential(\n","    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU()\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv_block_2): Sequential(\n","    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU()\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=640, out_features=59, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["sign_class_model_v1.state_dict()"],"metadata":{"id":"-nPQnuOz6iWW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Setting up loss function and optimizer for our model"],"metadata":{"id":"UHPcewOn7Zfm"}},{"cell_type":"code","source":["# Loss function\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# Optimizer\n","optimizer = torch.optim.SGD(params=sign_class_model_v1.parameters(),\n","                            lr=0.1)"],"metadata":{"id":"Tv6_pFaD0fXl","executionInfo":{"status":"ok","timestamp":1708574061757,"user_tz":-330,"elapsed":28,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Accuracy function for evaluation\n","def accuracy_fn(y_true, y_pred):\n","    \"\"\"\n","    Calculates accuracy between true labels and predicted labels\n","    Args:\n","      y_true (torch.Tensor): Ground Truth labels\n","      y_pred (torch.Tensor): Model predictions\n","    Returns:\n","      Accuracy value in parcentage % (torch.float)\n","    \"\"\"\n","    correct_values = torch.eq(y_true, y_pred).sum().item()\n","    accuracy = (correct_values / len(y_true)) * 100\n","    return accuracy"],"metadata":{"id":"D8iKInkO1RZB","executionInfo":{"status":"ok","timestamp":1708574061758,"user_tz":-330,"elapsed":28,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## Creating training step function for training our model in batches\n","\n","Steps:\n","1. Loop through epochs.\n","2. Loop through training batches, perform training steps"],"metadata":{"id":"IulvFBhX37ZR"}},{"cell_type":"code","source":["# Training Loop function\n","def train_step(model: torch.nn.Module,\n","               data_loader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               accuracy_fn,\n","               device: torch.device=device):\n","    \"\"\"\n","    performs training loop to learn on data loader\n","    \"\"\"\n","    train_loss, train_acc = 0, 0\n","\n","    # Put model in training mode\n","    model.train()\n","\n","    # Loop through training batches\n","    for batch, (X, y) in enumerate(data_loader):\n","        # Put data into target device\n","        X, y = X.to(device), y.to(device)\n","\n","        print(\"before model forward train\")\n","        # Forward pass\n","        y_pred = model(X)\n","        print(\"after model forward train\")\n","\n","        # Calculate loss and accuracy (per batch)\n","        loss = loss_fn(y_pred, y)\n","        # accumulating training loss and traiing accuracy accross epochs\n","        train_loss += loss\n","        train_acc += accuracy_fn(y_true=y,\n","                                 y_pred=y_pred.argmax(dim=1)) # going from logits --> prediction labels\n","\n","        # Optimizer zero grad\n","        optimizer.zero_grad()\n","\n","        # Loss backward\n","        loss.backward()\n","\n","        # Optimizer step (Update the model parameter once per batch)\n","        optimizer.step()\n","\n","    # Divide total train loss and accuracy by length of train dataloader to get the average value\n","    train_loss /= len(data_loader)\n","    train_acc /= len(data_loader)\n","    # Print vervose\n","    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")"],"metadata":{"id":"EdvsmXow59TD","executionInfo":{"status":"ok","timestamp":1708574061758,"user_tz":-330,"elapsed":27,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## Creating a validation step function for validating model on unseen data\n","Steps:\n","1. Put model to inference mode\n","2. Loop through testing batches, perform testing steps, calculate test loss per batch"],"metadata":{"id":"3sdsN7qv5VsW"}},{"cell_type":"code","source":["# Testing / Validation loop\n","def val_step(model: torch.nn.Module,\n","             data_loader: torch.utils.data.DataLoader,\n","             loss_fn: torch.nn.Module,\n","             accuracy_fn,\n","             device: torch.device=device):\n","    \"\"\"\n","    This function performs a validation loop step over our dataloader\n","    \"\"\"\n","    val_loss, val_acc = 0, 0\n","\n","    # Put model in eval mode\n","    model.eval()\n","\n","    # Turning on inference mode contaxt manager\n","    with torch.inference_mode():\n","        # Loop through data loader:\n","        for X, y in data_loader:\n","            X, y = X.to(device), y.to(device)\n","\n","            # Forward pass\n","            val_pred = model(X)\n","\n","            # Calculate loss and accuracy\n","            val_loss += loss_fn(val_pred, y)\n","            val_acc += accuracy_fn(y_true=y,\n","                                   y_pred=val_pred.argmax(dim=1)) # go from raw logits to prediction labels\n","\n","        # Getting the average validation loss and validation accuracy\n","        val_loss /= len(data_loader)\n","        val_acc /= len(data_loader)\n","        # Print vervose\n","        print(f\"Validation loss: {val_loss:.5f} | Validation Accuracy: {val_acc:.2f}%\")\n"],"metadata":{"id":"laHnIYT6-AJ8","executionInfo":{"status":"ok","timestamp":1708574061758,"user_tz":-330,"elapsed":26,"user":{"displayName":"Sipan Pal","userId":"06720679291462745205"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["## Now creating final model traing and validation loop"],"metadata":{"id":"2zQEhbcWBtcT"}},{"cell_type":"code","source":["if device == \"cuda\":\n","    torch.cuda.manual_seed(50)\n","elif device == \"cpu\":\n","    torch.manual_seed(50)\n","\n","# Setting epoch value\n","epochs = 1\n","\n","# Main Loop\n","for epoch in tqdm(range(epochs)):\n","    print(f\"Epoch: {epoch}\\n------->\")\n","    train_step(model=sign_class_model_v1,\n","               data_loader=train_loader,\n","               loss_fn=loss_fn,\n","               optimizer=optimizer,\n","               accuracy_fn=accuracy_fn,\n","               device=device)\n","    val_step(model=sign_class_model_v1,\n","             data_loader=validation_loader,\n","             loss_fn=loss_fn,\n","             accuracy_fn=accuracy_fn,\n","             device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c47d9cf639d644ef8284ead30faab494","081e69b1e7fb4df5a83ec612ced8fcdf","9a6abadda4214a58a5c92f8e1c3e6d8e","34f2848bd44c446bad888151cdd19f61","6049197dd9fa4547827a5049f84fb49c","9d3d8d9a2abe4d1c94792870e7b02ad5","476214ccb4cd40c2b16829e8834e8a4e","b6a5ef260c5542258640ce291bcfe03b","32a8b8d30e0a4573ab4a6d44f995b358","3a92f1c514e940c28d41716f0b60cfaa","cb8560d3080a4d7cb35ccd285ffdc8b8"]},"id":"JmraSA42B0YM","outputId":"1c30920c-13c0-4f0c-dda7-caa82feb6ebc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c47d9cf639d644ef8284ead30faab494"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 0\n","------->\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n","before model forward train\n","after model forward train\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ejJUWOJZEVba"},"execution_count":null,"outputs":[]}]}